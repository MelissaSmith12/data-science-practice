{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this program is to take a list of search results from Archive of Our Own and return a more customized set of search results. In particular, this program returns the stories with a fic quality rating, simply calculated by dividing the number of kudos plus the number of bookmarks by the number of reads. Eventually, this calculation may become more nuanced, including accounting for series. \n",
    "\n",
    "Inputs:\n",
    "    AO3 URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import string\n",
    "from lxml import html\n",
    "\n",
    "base_url = \"http://archiveofourown.org\"\n",
    "search_url = \"http://archiveofourown.org/tags/Sherlock%20Holmes*s*Sarah%20Sawyer*s*John%20Watson/works?page=\"\n",
    "#search_url = \"http://archiveofourown.org/tags/Clint%20Barton*s*Phil%20Coulson/works?page=\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_url(link_url):\n",
    "    file = urlopen(link_url)\n",
    "    soup = BeautifulSoup(file, \"lxml\")\n",
    "    stories = soup.ol\n",
    "    stories = soup.findAll(\"li\", { \"class\" : \"work blurb group\" })\n",
    "    return stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grab_max_page(link_url):\n",
    "    file = urlopen(link_url)\n",
    "    soup = BeautifulSoup(file, \"lxml\")\n",
    "    pages = soup.find(\"ol\", {\"class\": \"pagination actions\"})\n",
    "    index = len(pages.contents) - 3\n",
    "    max = pages.contents[index].a.contents[0]\n",
    "    return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grab_story(story1):\n",
    "    #Attempt to calculate score first\n",
    "    \n",
    "    try:   \n",
    "        hits = float(story1.findAll(\"dd\", { \"class\" : \"hits\" })[0].contents[0])\n",
    "        kudos = float(story1.findAll(\"dd\", {\"class\":\"kudos\"})[0].contents[0].contents[0])\n",
    "        bookmarks = float(story1.findAll(\"dd\", {\"class\": \"bookmarks\"})[0].contents[0].contents[0])\n",
    "        score = (kudos + bookmarks)/hits * 100\n",
    "    except IndexError:\n",
    "        return\n",
    "    else:  \n",
    "        characters = []\n",
    "        relationship = []\n",
    "        header = story1.find(\"h4\")\n",
    "        story_url = base_url + header.a['href']\n",
    "        title = header.a.contents[0]\n",
    "        #Need to navigate eiher to 2nd link in header or to rel = \"author\"\n",
    "        author = story1.find(\"a\", {\"rel\": \"author\"}).contents[0]\n",
    "        summary = story1.findAll(\"blockquote\", {\"class\": \"userstuff summary\"})[0].contents[1].contents[0]\n",
    "\n",
    "        #Store all tags as list\n",
    "        tags = \"\"    \n",
    "        language = \"\"\n",
    "        word_count = \"\"\n",
    "        chapters = \"\"\n",
    "#        temp = story1.findAll(\"li\", {\"class\": \"characters\"})[0]\n",
    "#        for item in temp:\n",
    "#            characters.append(item.contents[0].contents)\n",
    "        date = story1.findAll(\"p\", {\"class\":\"datetime\"})[0].contents[0]\n",
    "        relationship = []\n",
    "        temp = story1.findAll(\"li\", {\"class\": \"relationships\"})\n",
    "        for item in temp:\n",
    "            relationship.append(item.contents[0].contents[0])        \n",
    "    #    tags = story1.findAll\n",
    "        summary = story1.findAll(\"blockquote\", {\"class\": \"userstuff summary\"})[0].contents[1].contents[0]\n",
    "        keys = ['Title','Author', 'Characters', 'Relationship', 'Score', 'Summary', 'Hits', 'Kudos', 'URL', 'Date', 'Bookmarks']    \n",
    "        story_list.append(dict(zip(keys, [title, author, characters, relationship, score, summary, hits, kudos, story_url, date, bookmarks])))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "story_list = []\n",
    "page_number = 1\n",
    "link_url = search_url + str(page_number)\n",
    "max = int(grab_max_page(link_url))\n",
    "while page_number <= max:\n",
    "    stories = process_url(link_url)\n",
    "    for story in stories:\n",
    "        grab_story(story)\n",
    "    page_number += 1\n",
    "    link_url = search_url + str(page_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Author  Bookmarks Characters         Date     Hits  Kudos  \\\n",
      "21          Sadbhyl        8.0         []  10 Oct 2010    568.0   40.0   \n",
      "9           Sadbhyl       19.0         []   1 Jul 2011   1525.0   83.0   \n",
      "5      alizarin_nyc       11.0         []   4 Jan 2012   1893.0   92.0   \n",
      "2       Mazarin221b       28.0         []  23 Aug 2012   3110.0  139.0   \n",
      "11       Saathi1013       10.0         []   1 Apr 2011   2766.0  134.0   \n",
      "10      Pyjamapants      150.0         []  29 May 2011  13900.0  461.0   \n",
      "7    marysutherland        9.0         []   5 Nov 2011   1838.0   70.0   \n",
      "1         lie_to_me        1.0         []   7 Sep 2013    877.0   29.0   \n",
      "20       Saathi1013       24.0         []  13 Dec 2010   5319.0  151.0   \n",
      "17       Saathi1013        2.0         []  28 Dec 2010   2629.0   81.0   \n",
      "14       Saathi1013        2.0         []   1 Feb 2011   2797.0   85.0   \n",
      "16       Saathi1013        2.0         []   4 Jan 2011   2523.0   74.0   \n",
      "15       Saathi1013        2.0         []   7 Jan 2011   2530.0   74.0   \n",
      "0           deklava        8.0         []  24 Oct 2013   3139.0   86.0   \n",
      "8           Pouncer       12.0         []   1 Jul 2011   3054.0   79.0   \n",
      "13       Saathi1013        1.0         []   2 Feb 2011   2246.0   63.0   \n",
      "18       Saathi1013        4.0         []  23 Dec 2010   2950.0   78.0   \n",
      "12       Saathi1013        3.0         []   5 Mar 2011   3326.0   85.0   \n",
      "19       Saathi1013        5.0         []  15 Dec 2010   3585.0   88.0   \n",
      "3            mardia        2.0         []  25 Feb 2012   1920.0   44.0   \n",
      "4   nickelsandcoats        6.0         []  25 Jan 2012   2712.0   44.0   \n",
      "6              Dweo        4.0         []   1 Jan 2012   2003.0   31.0   \n",
      "\n",
      "                                         Relationship     Score  \\\n",
      "21                              [John/Sarah/Sherlock]  8.450704   \n",
      "9   [Sarah Sawyer/John Watson, Sherlock Holmes/Sar...  6.688525   \n",
      "5   [Sarah Sawyer/John Watson, Sherlock Holmes/Joh...  5.441099   \n",
      "2   [Sherlock Holmes/Sarah Sawyer/John Watson, She...  5.369775   \n",
      "11  [Sherlock Holmes/Sarah Sawyer/John Watson, Sar...  5.206074   \n",
      "10  [Sarah Sawyer/John Watson, Sherlock Holmes/Joh...  4.395683   \n",
      "7   [Mycroft Holmes/Lestrade (Inspector), Anthea/M...  4.298150   \n",
      "1   [Sherlock Holmes/John Watson, John Watson/Sara...  3.420753   \n",
      "20  [Sarah Sawyer/John Watson, Sherlock Holmes/Sar...  3.290092   \n",
      "17         [Sherlock Holmes/Sarah Sawyer/John Watson]  3.157094   \n",
      "14         [Sherlock Holmes/Sarah Sawyer/John Watson]  3.110476   \n",
      "16         [Sherlock Holmes/Sarah Sawyer/John Watson]  3.012287   \n",
      "15         [Sherlock Holmes/Sarah Sawyer/John Watson]  3.003953   \n",
      "0          [Sherlock Holmes/Sarah Sawyer/John Watson]  2.994584   \n",
      "8   [Sherlock Holmes/John Watson, John Watson/Sara...  2.979699   \n",
      "13  [Sherlock Holmes/Sarah Sawyer/John Watson, She...  2.849510   \n",
      "18         [Sherlock Holmes/Sarah Sawyer/John Watson]  2.779661   \n",
      "12         [Sherlock Holmes/Sarah Sawyer/John Watson]  2.645821   \n",
      "19  [Sarah Sawyer/John Watson, Sherlock Holmes/Sar...  2.594142   \n",
      "3          [Sherlock Holmes/Sarah Sawyer/John Watson]  2.395833   \n",
      "4   [Sherlock/John/Sarah - Relationship, Establish...  1.843658   \n",
      "6          [Sherlock Holmes/Sarah Sawyer/John Watson]  1.747379   \n",
      "\n",
      "                                              Summary  \\\n",
      "21  John always gets a rush after a case.  What he...   \n",
      "9   Sarah knew that Sherlock would be part of any ...   \n",
      "5   Sarah has a theory that she can't keep to hers...   \n",
      "2     Originally posted to LiveJournal April 1, 2011.   \n",
      "11  Sarah and John are on their honeymoon; Sherloc...   \n",
      "10  Sarah and John discover that inviting Sherlock...   \n",
      "7                        Written for a prompt at the    \n",
      "1   In which John has rather a lot of surprising c...   \n",
      "20  Sarah struggles with dating John, while Sherlo...   \n",
      "17  Sherlock evaluates his data, Sarah uncovers a ...   \n",
      "14  Sarah, in Moriarty's clutches; John and Sherlo...   \n",
      "16  Sherlock recovers under John's care, while Sar...   \n",
      "15  In Which Compromises are Made, as are Plans; S...   \n",
      "0                                                   \n",
      "   \n",
      "8   Sherlock lay on the sofa and moaned.  Fever wa...   \n",
      "13  What it says on the tin.  'Bonus material' for...   \n",
      "18  The original summary reads thus: “I have badly...   \n",
      "12  In which someone dies and their funeral is hel...   \n",
      "19  FULL TITLE: \"Problems & Solutions, or: A Brief...   \n",
      "3                         Written for Porn Battle XI.   \n",
      "4                        This is John Watson, broken.   \n",
      "6            The boys just want make Sarah feel good.   \n",
      "\n",
      "                                                Title  \\\n",
      "21                                    Stress Reaction   \n",
      "9                              Baker Street Courtship   \n",
      "5                                              ALLIES   \n",
      "2                       The Seduction of Sarah Sawyer   \n",
      "11                                 Wish You Were Here   \n",
      "10  The Comparative Uses of Semaphore and Foghorns...   \n",
      "7                             The Penultimate Problem   \n",
      "1   Two Conversations John Didn't Want to Have, an...   \n",
      "20                                         Surveilled   \n",
      "17                               City Sirens, Violins   \n",
      "14                                        Lorem Ipsum   \n",
      "16                     The Trick is to Keep Breathing   \n",
      "15                                Grace to the Strong   \n",
      "0                                            Triangle   \n",
      "8                          A Recollection Half Erased   \n",
      "13  DELETED SCENES from Lorem Ipsum (story #7 from...   \n",
      "18                                  Bohemian Like You   \n",
      "12                                  One Day Like This   \n",
      "19                        Problems & Solutions, or...   \n",
      "3                           delivering her from grace   \n",
      "4   I’ve Shattered into a Thousand Pieces (We’ll P...   \n",
      "6                             An Equilateral Triangle   \n",
      "\n",
      "                                         URL  \n",
      "21   http://archiveofourown.org/works/161916  \n",
      "9    http://archiveofourown.org/works/217713  \n",
      "5    http://archiveofourown.org/works/313231  \n",
      "2    http://archiveofourown.org/works/494037  \n",
      "11   http://archiveofourown.org/works/438864  \n",
      "10   http://archiveofourown.org/works/177724  \n",
      "7    http://archiveofourown.org/works/273026  \n",
      "1    http://archiveofourown.org/works/927081  \n",
      "20   http://archiveofourown.org/works/438655  \n",
      "17   http://archiveofourown.org/works/438720  \n",
      "14   http://archiveofourown.org/works/438771  \n",
      "16   http://archiveofourown.org/works/438732  \n",
      "15   http://archiveofourown.org/works/438748  \n",
      "0   http://archiveofourown.org/works/1016599  \n",
      "8    http://archiveofourown.org/works/217923  \n",
      "13   http://archiveofourown.org/works/438868  \n",
      "18   http://archiveofourown.org/works/438704  \n",
      "12   http://archiveofourown.org/works/438779  \n",
      "19   http://archiveofourown.org/works/438668  \n",
      "3    http://archiveofourown.org/works/347022  \n",
      "4    http://archiveofourown.org/works/263451  \n",
      "6    http://archiveofourown.org/works/309659  \n"
     ]
    }
   ],
   "source": [
    "story_list_df = pd.DataFrame(story_list)\n",
    "sorted_stories = story_list_df.sort_values(by=\"Score\", ascending=False, inplace=False, kind='quicksort', na_position='last')\n",
    "print sorted_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
